modules/lambda/main.tf: |
  resource "aws_lambda_function" "processor" {
    function_name = var.function_name
    role          = aws_iam_role.lambda.arn
    handler       = var.handler
    runtime       = var.runtime
    timeout       = var.timeout
    memory_size   = var.memory_size

    filename         = data.archive_file.lambda.output_path
    source_code_hash = data.archive_file.lambda.output_base64sha256

    environment {
      variables = merge(var.base_env_vars, var.custom_env_vars)
    }

    tracing_config {
      mode = var.tracing_mode
    }

    tags = var.tags
  }

  resource "aws_iam_role" "lambda" {
    name = "${var.function_name}-role"

    assume_role_policy = jsonencode({
      Version = "2012-10-17"
      Statement = [{
        Effect    = "Allow"
        Principal = { Service = "lambda.amazonaws.com" }
        Action    = "sts:AssumeRole"
      }]
    })
  }

  resource "aws_iam_role_policy_attachment" "lambda_basic" {
    role       = aws_iam_role.lambda.name
    policy_arn = "arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole"
  }

  data "archive_file" "lambda" {
    type        = "zip"
    source_dir  = var.source_dir
    output_path = "${path.module}/function.zip"
  }
modules/lambda/variables.tf: |
  variable "function_name" {
    type = string
  }

  variable "handler" {
    type    = string
    default = "index.handler"
  }

  variable "runtime" {
    type    = string
    default = "nodejs18.x"
  }

  variable "timeout" {
    type    = number
    default = 30
  }

  variable "memory_size" {
    type    = number
    default = 128
  }

  variable "source_dir" {
    type = string
  }

  variable "base_env_vars" {
    type    = map(string)
    default = {}
  }

  variable "custom_env_vars" {
    type    = map(string)
    default = {}
  }

  variable "tracing_mode" {
    type    = string
    default = "PassThrough"
  }

  variable "tags" {
    type    = map(string)
    default = {}
  }
app.py: |
  import os
  db_host = os.environ.get('DB_HOST')
  print(f'Connecting to {db_host}')
infrastructure/processor.tf: |
  module "data_processor" {
    source        = "./modules/lambda"
    function_name = "data-processor"
    handler       = "processor.handle"
    runtime       = "python3.9"
    source_dir    = "${path.module}/../functions/processor"

    base_env_vars = {
      LOG_LEVEL = "INFO"
      REGION    = var.aws_region
    }

    tags = local.common_tags
  }
unrelated/codepipeline.tf: |
  # GARBAGE_TF_PIPELINE_442_001
  resource "aws_codepipeline" "unrelated_pipeline" {
    name     = "GARBAGE_PIPELINE_442_002"
    role_arn = "arn:aws:iam::123456789:role/GARBAGE_ROLE_442_003"

    artifact_store {
      location = "GARBAGE_BUCKET_442_004"
      type     = "S3"
    }

    stage {
      name = "GARBAGE_SOURCE_442_005"
      action {
        name     = "Source"
        category = "Source"
        owner    = "AWS"
        provider = "S3"
        version  = "1"
        output_artifacts = ["source_output"]
        configuration = {
          S3Bucket    = "GARBAGE_BUCKET_442_004"
          S3ObjectKey = "source.zip"
        }
      }
    }
  }
unrelated/elasticache.tf: |
  # GARBAGE_TF_CACHE_442_006
  resource "aws_elasticache_cluster" "unrelated_cache" {
    cluster_id           = "GARBAGE-CACHE-442-007"
    engine               = "redis"
    node_type            = "cache.t3.micro"
    num_cache_nodes      = 1
    parameter_group_name = "default.redis7"
    port                 = 6379
  }

  variable "GARBAGE_CACHE_VAR_442_008" {
    default = "unrelated"
  }
