worker.py: "import time\nimport os\nimport argparse\nimport signal\nimport sys\nfrom typing import Optional\n\nCONCURRENCY = int(os.getenv(\"WORKER_CONCURRENCY\", \"1\"))\nQUEUE_NAME = os.getenv(\"QUEUE_NAME\"\
  , \"default\")\n\nshutdown_requested = False\n\ndef signal_handler(signum, frame):\n    global shutdown_requested\n    print(f\"Received signal {signum}, initiating graceful shutdown...\")\n    shutdown_requested\
  \ = True\n\ndef process_jobs(concurrency: int, queue: str, verbose: bool = False):\n    signal.signal(signal.SIGTERM, signal_handler)\n    signal.signal(signal.SIGINT, signal_handler)\n\n    print(f\"\
  Worker starting with concurrency={concurrency}, queue={queue}\")\n\n    while not shutdown_requested:\n        if verbose:\n            print(f\"Processing jobs from {queue}...\")\n        time.sleep(10)\n\
  \n    print(\"Worker shutdown complete\")\n\ndef parse_args():\n    parser = argparse.ArgumentParser(description=\"Job worker\")\n    parser.add_argument(\"--concurrency\", type=int, default=CONCURRENCY)\n\
  \    parser.add_argument(\"--queue\", type=str, default=QUEUE_NAME)\n    parser.add_argument(\"--verbose\", \"-v\", action=\"store_true\")\n    return parser.parse_args()\n\nif __name__ == \"__main__\"\
  :\n    args = parse_args()\n    process_jobs(args.concurrency, args.queue, args.verbose)\n"
scheduler.py: "import time\nimport schedule\nfrom typing import Callable\n\ndef run_job(job_name: str):\n    print(f\"Running scheduled job: {job_name}\")\n\ndef setup_schedule():\n    schedule.every(1).hour.do(run_job,\
  \ \"hourly_cleanup\")\n    schedule.every().day.at(\"00:00\").do(run_job, \"daily_report\")\n\ndef run_scheduler():\n    setup_schedule()\n    while True:\n        schedule.run_pending()\n        time.sleep(60)\n\
  \nif __name__ == \"__main__\":\n    run_scheduler()\n"
requirements.txt: 'schedule==1.2.0

  redis==5.0.0

  '
Dockerfile: 'FROM python:3.12-slim

  WORKDIR /app

  COPY requirements.txt .

  RUN pip install -r requirements.txt

  COPY *.py ./

  CMD ["python", "worker.py"]

  '
docker-compose.yml: "version: '3.8'\n\nservices:\n  worker:\n    build:\n      context: .\n      dockerfile: Dockerfile\n    command: [\"python\", \"-u\", \"worker.py\", \"--concurrency\", \"4\", \"--queue\"\
  , \"high-priority\", \"--verbose\"]\n    environment:\n      - WORKER_CONCURRENCY=4\n      - QUEUE_NAME=high-priority\n      - PYTHONUNBUFFERED=1\n    restart: always\n    stop_grace_period: 30s\n   \
  \ deploy:\n      mode: replicated\n      replicas: 3\n      resources:\n        limits:\n          cpus: '0.5'\n          memory: 256M\n\n  worker-low:\n    build:\n      context: .\n      dockerfile:\
  \ Dockerfile\n    command:\n      - python\n      - -u\n      - worker.py\n      - --concurrency\n      - \"2\"\n      - --queue\n      - low-priority\n    environment:\n      - PYTHONUNBUFFERED=1\n \
  \   restart: unless-stopped\n    profiles:\n      - background\n\n  scheduler:\n    build:\n      context: .\n      dockerfile: Dockerfile\n    command: python scheduler.py\n    restart: always\n    deploy:\n\
  \      mode: replicated\n      replicas: 1\n\n  shell:\n    build:\n      context: .\n      dockerfile: Dockerfile\n    entrypoint: [\"/bin/sh\"]\n    command: [\"-c\", \"while true; do sleep 86400; done\"\
  ]\n    stdin_open: true\n    tty: true\n    profiles:\n      - debug\n\n  one-off:\n    build:\n      context: .\n      dockerfile: Dockerfile\n    command: [\"python\", \"-c\", \"print('One-off task\
  \ completed')\"]\n    restart: \"no\"\n    profiles:\n      - tasks\n"
scripts/start_worker.sh: '#!/bin/bash

  docker-compose up worker

  '
tests/test_worker.py: "def test_process_jobs():\n    pass\n"
docs/workers.md: '# Worker Configuration

  '
k8s/job.yaml: 'apiVersion: batch/v1

  '
celery/config.py: ''
